{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 20:27:07.874309: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-21 20:27:07.927303: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-21 20:27:08.845236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "import sys\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM, LlamaTokenizer\n",
    "import json\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device kernel image is invalid\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data4/polyakov/instruction_tuning/data/Llama-2-7b-chat-hf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(base_model, local_files_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/transformers/modeling_utils.py:3102\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3097\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   3098\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has some weights that should be kept in higher precision, you need to upgrade \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3099\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`accelerate` to properly deal with them (`pip install --upgrade accelerate`).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3100\u001b[0m     )\n\u001b[1;32m   3101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_map \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequential\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 3102\u001b[0m     max_memory \u001b[38;5;241m=\u001b[39m \u001b[43mget_balanced_memory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_zero\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbalanced_low_0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3107\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdevice_map_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3108\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3110\u001b[0m     max_memory \u001b[38;5;241m=\u001b[39m get_max_memory(max_memory)\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/accelerate/utils/modeling.py:771\u001b[0m, in \u001b[0;36mget_balanced_memory\u001b[0;34m(model, max_memory, no_split_module_classes, dtype, special_dtypes, low_zero)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;66;03m# Get default / clean up max_memory\u001b[39;00m\n\u001b[1;32m    770\u001b[0m user_not_set_max_memory \u001b[38;5;241m=\u001b[39m max_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 771\u001b[0m max_memory \u001b[38;5;241m=\u001b[39m \u001b[43mget_max_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_memory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_xpu_available():\n\u001b[1;32m    774\u001b[0m     num_devices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m([d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m max_memory \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(d)\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m max_memory[d] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/accelerate/utils/modeling.py:643\u001b[0m, in \u001b[0;36mget_max_memory\u001b[0;34m(max_memory)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_xpu_available():\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()):\n\u001b[0;32m--> 643\u001b[0m         _ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m     max_memory \u001b[38;5;241m=\u001b[39m {i: torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmem_get_info(i)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())}\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device kernel image is invalid\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "base_model = '/data4/polyakov/instruction_tuning/data/Llama-2-7b-chat-hf'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        load_in_4bit=True,\n",
    "        local_files_only=True,\n",
    "        device_map='auto',\n",
    ")\n",
    "model.config.use_cache = False\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/transformers/generation/utils.py:1421: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/transformers/generation/utils.py:1539: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Plastic\n"
     ]
    }
   ],
   "source": [
    "curr_prompt = \"What does the fllowing sentence say? Translate to english. \\u6c7d\\u6c34\\u74f6\\u5851\\u6599\\u676f\\u900f\\u660e\\u78e8\\u7802\\u4fbf\\u643a\\u4e0d\\u6613\\u6454\\u7834\\u5bc6\\u5c01\\u540a\\u5e26\\u5976\\u8336\\u676f\\u6c34\\u676f\\u505a\\u793c\\u54c1 Translation:\"\n",
    "tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "res = model.generate(tokenized, max_length=tokenized.shape[1] + 2)\n",
    "print(tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "You are you will be given api calls from some model and api outputs from rapidapi apis. \n",
    "Sometimes api return errors. \n",
    "It is hard to parse them using rule-based methods. \n",
    "An api may respond with an empty output (it could be empty list, or an empty dict), contain a field that states it is an error or etc.\n",
    "You will be given 5 examples. You should respond only \"Yes\" if the response does not contain errors from an api and \"No\" if not.\n",
    "Please make shure that api returned what the api call requested. If not, return \"No\"\n",
    "Examples:\n",
    "API Call:\n",
    "Thought: To fulfill the user's request for gathering user information and recent media posts from Instagram for a specific username 'nike', I previously called the 'userinfo_for_instagram_cheapest' function with the argument {\"username\": \"nike\"}. By doing so, I efficiently retrieved the desired user data, including their biography, bio links, biographical information, and other relevant details. Now, to proceed with accessing the user's recent media posts, I will call the 'user_medias_for_instagram_cheapest' function with the argument {\"user_id\": \"113294420064920\"}. This will allow me to retrieve the most recent media posts of the user 'nike' and provide the user with the requested data effectively.\n",
    "Action: user_medias_for_instagram_cheapest\n",
    "Action Input: {\n",
    "  \"user_id\": \"113294420064920\"\n",
    "}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"{'items': [], 'num_results': 0, 'status': 'ok'}\"}\n",
    "Result:\n",
    "No\n",
    "###\n",
    "API Call:\n",
    "Thought: The user requested the list of languages supported by the LanguageTool API for grammar and writing assistance. To fulfill this request, I need to call the \"list_of_languages_for_languagetool\" function without any arguments. By doing so, I expect to receive the complete list of supported languages. This information will be crucial for implementing multilingual support in the project, ensuring accurate grammar and writing assistance for different languages.\n",
    "Action: list_of_languages_for_languagetool\n",
    "Action Input: {}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"[{'name': 'Arabic', 'code': 'ar', 'longCode': 'ar'}, {'name': 'Asturian', 'code': 'ast', 'longCode': 'ast-ES'}, {'name': 'Belarusian', 'code': 'be', 'longCode': 'be-BY'}, {'name': 'Breton', 'code': 'br', 'longCode': 'br-FR'}, {'name': 'Catalan', 'code': 'ca', 'longCode': 'ca-ES'}, {'name': 'Catalan (Valencian)', 'code': 'ca', 'longCode': 'ca-ES-valencia'}, {'name': 'Catalan (Balearic)', 'code': 'ca', 'longCode': 'ca-ES-balear'}, {'name': 'Danish', 'code': 'da', 'longCode': 'da-DK'}, {'name': 'German', 'code': 'de', 'longCode': 'de'}, {'name': 'German (Germany)', 'code': 'de', 'longCode': 'de-DE'}, {'name': 'German (Austria)', 'code': 'de', 'longCode': 'de-AT'}, {'name': 'German (Swiss)', 'code': 'de', 'longCode': 'de-CH'}, {'name': 'Simple German', 'code': 'de-DE-x-simple-language', 'longCode': 'de-DE-x-simple-language'}, {'name': 'Greek', 'code': 'el', 'longCode': 'el-GR'}, {'name': 'English', 'code': 'en', 'longCode': 'en'}, {'name': 'English (US)', 'code': 'en', 'longCode': 'en-U..\n",
    "Result:\n",
    "Yes\n",
    "###\n",
    "API Call:\n",
    "Thought: I will now call the \"dividends_for_freedom_finance\" function to retrieve information about dividends for the symbol \"AMZN\". By using the argument {\"symbol\": \"AMZN\"}, I can focus specifically on the dividends related to the stock \"AMZN\". This function will help me analyze the dividend history for \"AMZN\" and provide the user with the requested information.\n",
    "Action: dividends_for_freedom_finance\n",
    "Action Input: {\n",
    "\"symbol\": \"AMZN\"\n",
    "}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"{'total': 0, 'offset': 0, 'results': [], 'responseStatus': None}\"}\n",
    "Result:\n",
    "No\n",
    "###\n",
    "API Call:\n",
    "Thought: To gather the required information for integrating APIs into the company's website, I can call the \"list_all_api_for_testing_for_my_use\" function. This function will provide me with descriptions, methods, required parameters, and optional parameters for each API. With this information, I can analyze and compare the APIs to make an informed decision.\n",
    "Action: list_all_api_for_testing_for_my_use\n",
    "Action Input: {}\n",
    "API Response:\n",
    "{\"error\": \"Unauthorized error...\", \"response\": \"{'1forge.com': {'added': '2017-05-30T08:34:14.000Z', 'preferred': '0.0.1', 'versions': {'0.0.1': {'added': '2017-05-30T08:34:14.000Z', 'info': {'contact': {'email': 'contact@1forge.com', 'name': '1Forge', 'url': 'http://1forge.com'}, 'description': 'Stock and Forex Data and Realtime Quotes', 'title': '1Forge Finance APIs', 'version': '0.0.1', 'x-apisguru-categories': ['financial'], 'x-logo': {'backgroundColor': '#24292e', 'url': 'https://api.apis.guru/v2/cache/logo/https_1forge.com_assets_images_f-blue.svg'}, 'x-origin': [{'format': 'swagger', 'url': 'http://1forge.com/openapi.json', 'version': '2.0'}], 'x-providerName': '1forge.com'}, 'updated': '2017-06-27T16:49:57.000Z', 'swaggerUrl': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1/swagger.json', 'swaggerYamlUrl': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1/swagger.yaml', 'openapiVer': '2.0', 'link': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1.json'}}}, '1password.com:events': {'added': '2021-07-19...\n",
    "Result:\n",
    "No\n",
    "###\n",
    "API Call:\n",
    "Thought: I need to gather user information for a specific Instagram username, 'nike', as requested by the user. They also want access to the user's recent media posts. To achieve this, I will call the 'userinfo_for_instagram_cheapest' function with the argument of {\"username\": \"nike\"}. This will help me retrieve the desired data efficiently and fulfill the user's request effectively.\n",
    "Action: userinfo_for_instagram_cheapest\n",
    "Action Input: {\n",
    "  \"username\": \"nike\"\n",
    "}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"{'data': {'user': {'biography': 'Spotlighting athlete* and\\\\xa0\\ud83d\\udc5f\\\\xa0stories\\\\n#BlackLivesMatter, #StopAsianHate, and #NoPrideNoSport', 'bio_links': [{'title': '', 'lynx_url': 'https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fnike&e=AT063fG4N158ZbZOaZ_A32batiXwR-0Yih5XNa5wfSNPCiDo546PSV0a8mm72ElVxWgNJdgYeHNOTMMTOe_kn7R-C-f2N9ym', 'url': 'https://linkin.bio/nike', 'link_type': 'external'}], 'biography_with_entities': {'raw_text': 'Spotlighting athlete* and\\\\xa0\\ud83d\\udc5f\\\\xa0stories\\\\n#BlackLivesMatter, #StopAsianHate, and #NoPrideNoSport', 'entities': [{'user': None, 'hashtag': {'name': 'nopridenosport'}}, {'user': None, 'hashtag': {'name': 'stopasianhate'}}, {'user': None, 'hashtag': {'name': 'blacklivesmatter'}}]}, 'blocked_by_viewer': False, 'restricted_by_viewer': None, 'country_block': False, 'eimu_id': '113294420064920', 'external_url': 'https://linkin.bio/nike', 'external_url_linkshimmed': 'https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fnike&e=AT04S69...\n",
    "Result:\n",
    "Yes\n",
    "###\n",
    "API Call: \n",
    "<api_call>\n",
    "API Response:\n",
    "<api_response>\n",
    "Result:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_zero_shot = '''\n",
    "You are you will be api calls from some model and api outputs from rapidapi apis. \n",
    "Sometimes api return errors. \n",
    "It is hard to parse them using rule-based methods. \n",
    "An api may respond with an empty output (it could be empty list, or an empty dict), contain a field that states it is an error or etc.\n",
    "You will be given 5 examples. You should respond only \"Yes\" if the response does not contain errors from an api and \"No\" if not.\n",
    "Please make shure that api returned what the api call requested. If not, return \"No\"\n",
    "You will be given data in the folllowing format.\n",
    "API Call: \n",
    "api_call\n",
    "API Response:\n",
    "api_response\n",
    "Result: \n",
    "Yes/No\n",
    "Begin!\n",
    "###\n",
    "API Call: \n",
    "<api_call>\n",
    "API Response:\n",
    "<api_response>\n",
    "Result:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('/data4/polyakov/instruction_tuning/ToolBench/data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_this_is_not_the_first_time_you_tried.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Call:\n",
      "\n",
      "Thought: I need to gather user information for a specific Instagram username, 'nike', as requested by the user. They also want access to the user's recent media posts. To achieve this, I will call the 'userinfo_for_instagram_cheapest' function with the argument of {\"username\": \"nike\"}. This will help me retrieve the desired data efficiently and fulfill the user's request effectively.\n",
      "Action: userinfo_for_instagram_cheapest\n",
      "Action Input: {\n",
      "  \"username\": \"nike\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'data': {'user': {'biography': 'Spotlighting athlete* and\\\\xa0\\ud83d\\udc5f\\\\xa0stories\\\\n#BlackLivesMatter, #StopAsianHate, and #NoPrideNoSport', 'bio_links': [{'title': '', 'lynx_url': 'https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fnike&e=AT063fG4N158ZbZOaZ_A32batiXwR-0Yih5XNa5wfSNPCiDo546PSV0a8mm72ElVxWgNJdgYeHNOTMMTOe_kn7R-C-f2N9ym', 'url': 'https://linkin.bio/nike', 'link_type': 'external'}], 'biography_with_entities': {'raw_text': 'Spotlighting athlete* and\\\\xa0\\ud83d\\udc5f\\\\xa0stories\\\\n#BlackLivesMatter, #StopAsianHate, and #NoPrideNoSport', 'entities': [{'user': None, 'hashtag': {'name': 'nopridenosport'}}, {'user': None, 'hashtag': {'name': 'stopasianhate'}}, {'user': None, 'hashtag': {'name': 'blacklivesmatter'}}]}, 'blocked_by_viewer': False, 'restricted_by_viewer': None, 'country_block': False, 'eimu_id': '113294420064920', 'external_url': 'https://linkin.bio/nike', 'external_url_linkshimmed': 'https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fnike&e=AT04S69...\n",
      "Result:\n",
      " Yes\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: To fulfill the user's request for gathering user information and recent media posts from Instagram for a specific username 'nike', I previously called the 'userinfo_for_instagram_cheapest' function with the argument {\"username\": \"nike\"}. By doing so, I efficiently retrieved the desired user data, including their biography, bio links, biographical information, and other relevant details. Now, to proceed with accessing the user's recent media posts, I will call the 'user_medias_for_instagram_cheapest' function with the argument {\"user_id\": \"113294420064920\"}. This will allow me to retrieve the most recent media posts of the user 'nike' and provide the user with the requested data effectively.\n",
      "Action: user_medias_for_instagram_cheapest\n",
      "Action Input: {\n",
      "  \"user_id\": \"113294420064920\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'items': [], 'num_results': 0, 'status': 'ok'}\"}\n",
      "Result:\n",
      " No\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: I am calling the Chuck Norris API to generate a random joke about Chuck Norris in response to the user's request. This will provide an amusing and entertaining response for the user.\n",
      "Action: jokes_random_for_chuck_norris\n",
      "Action Input: {}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{\\\"categories\\\":[],\\\"created_at\\\":\\\"2020-01-05 13:42:28.143137\\\",\\\"icon_url\\\":\\\"https://assets.chucknorris.host/img/avatar/chuck-norris.png\\\",\\\"id\\\":\\\"w1QcOOGdStm9Wz27-AKCIw\\\",\\\"updated_at\\\":\\\"2020-01-05 13:42:28.143137\\\",\\\"url\\\":\\\"https://api.chucknorris.io/jokes/w1QcOOGdStm9Wz27-AKCIw\\\",\\\"value\\\":\\\"Chuck Norris doesn't clip his fingernails... he rips them out with his bare hands and regrows new ones immediately.\\\"}\"}\n",
      "Result:\n",
      " Yes</s>\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: I am calling the 'get_math_fact_for_numbers' API with the argument {'number': '1729'}. This API call is made to provide the user with a fascinating mathematical property about the number 1729. By retrieving this information, I can fulfill the user's request for an interesting fact about the number.\n",
      "Action: get_math_fact_for_numbers\n",
      "Action Input: {\n",
      "  \"number\": \"1729\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'text': 'the smallest natural number representable in two different ways as a sum of two positive cubes, as Ramanujan stated on the spot', 'number': 1729, 'found': True, 'type': 'math'}\"}\n",
      "Result:\n",
      " Yes</s>\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: To fetch the list of languages supported by the Microsoft Translator Text API, I called the \"languages_for_microsoft_translator_text\" function with the argument \"api_version\" set to \"3.0\". The reason for this API call is that the user requested the list of languages supported by this API. By providing the \"api_version\" argument, I ensured that I am accessing the latest version of the API. This will help me gather the necessary information to support multilingual functionality in the project.\n",
      "Action: languages_for_microsoft_translator_text\n",
      "Action Input: {\n",
      "  \"api_version\": \"3.0\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"\\u001f\\ufffd\\b\\u0000\\u0000\\u0000\\u0000\\u0000\\u0004\\u0000\\ufffd][o\\u001bG\\ufffd\\ufffd+\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\u0007\\ufffd-\\ufffd\\ufffd\\ufffd\\ufffdK<\\ufffd\\ufffd\\ufffd\\ufffdE\\u001e\\ufffdb\\ufffdl\\ufffd\\ufffd-\\ufffdE\\u001a*0 Y\\u001e\\u0271\\ufffd\\u001d;\\u0019K\\ufffdmX\\ufffd\\ufffd\\u000b\\ufffd\\ufffdBQ\\ufffd%K\\ufffd\\ufffd@\\ufffda\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdR\\f\\u0018E$cg&\\ufffd\\ufffda\\ufffd\\ufffdl\\ufffd\\ufffdO5\\ufffd\\ufffd\\u0005\\u0006v\\u0010\\ufffd\\ufffd\\ufffdy\\ufffd\\ufffd\\ua72aS\\ufffdTWW}\\u06a2\\ufffdH\\ufffd$\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdO[P\\ufffd\\ufffd)\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdU1\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdH\\u0017\\ufffd\\ufffd\\ufffd\\ufffdBBTI\\ufffd\\ufffd\\ufffd-\\ufffd\\ufffd\\ufffd\\ufffd\\f-\\ufffdI!U\\ufffdr\\nW\\ufffdOU\\ufffd\\u076b\\\\[\\ufffd\\\\\\ufffd\\u0007\\ufffdUZ^Eq(~0\\u007fx\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdA\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd:\\ufffd\\ufffdK\\u0016\\ufffdF\\u0003h\\u001a\\ufffd\\ufffd\\tN\\b<\\ufffd{<\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd \\ufffd[\\ufffdsO\\ufffd\\ufffd\\u001e\\ufffd2@#\\...\n",
      "Result:\n",
      " No\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: I called the \"ages_by_this_api_endpoint_for_simple_elegant_translation_service\" function without any arguments. This API call is made to fetch the list of languages supported by the Simple & Elegant Translation Service API. By not providing any arguments, I expect to receive the complete list of supported languages. This information will be helpful for implementing multilingual support in the project.\n",
      "Action: ages_by_this_api_endpoint_for_simple_elegant_translation_service\n",
      "Action Input: {}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'languages': {'af': 'afrikaans', 'am': 'amharic', 'ar': 'arabic', 'az': 'azerbaijani', 'be': 'belarusian', 'bg': 'bulgarian', 'bn': 'bengali', 'bs': 'bosnian', 'ca': 'catalan', 'ceb': 'cebuano', 'co': 'corsican', 'cs': 'czech', 'cy': 'welsh', 'da': 'danish', 'de': 'german', 'el': 'greek', 'en': 'english', 'eo': 'esperanto', 'es': 'spanish', 'et': 'estonian', 'eu': 'basque', 'fa': 'persian', 'fi': 'finnish', 'fil': 'Filipino', 'fr': 'french', 'fy': 'frisian', 'ga': 'irish', 'gd': 'scots gaelic', 'gl': 'galician', 'gu': 'gujarati', 'ha': 'hausa', 'haw': 'hawaiian', 'he': 'Hebrew', 'hi': 'hindi', 'hmn': 'hmong', 'hr': 'croatian', 'ht': 'haitian creole', 'hu': 'hungarian', 'hy': 'armenian', 'id': 'indonesian', 'ig': 'igbo', 'is': 'icelandic', 'it': 'italian', 'iw': 'hebrew', 'ja': 'japanese', 'jw': 'javanese', 'ka': 'georgian', 'kk': 'kazakh', 'km': 'khmer', 'kn': 'kannada', 'ko': 'korean', 'ku': 'kurdish (kurmanji)', 'ky': 'kyrgyz', 'la': 'latin', 'lb': 'luxembourgish', 'lo': 'lao', '...\n",
      "Result:\n",
      " Yes\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: The user requested the list of languages supported by the LanguageTool API for grammar and writing assistance. To fulfill this request, I need to call the \"list_of_languages_for_languagetool\" function without any arguments. By doing so, I expect to receive the complete list of supported languages. This information will be crucial for implementing multilingual support in the project, ensuring accurate grammar and writing assistance for different languages.\n",
      "Action: list_of_languages_for_languagetool\n",
      "Action Input: {}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"[{'name': 'Arabic', 'code': 'ar', 'longCode': 'ar'}, {'name': 'Asturian', 'code': 'ast', 'longCode': 'ast-ES'}, {'name': 'Belarusian', 'code': 'be', 'longCode': 'be-BY'}, {'name': 'Breton', 'code': 'br', 'longCode': 'br-FR'}, {'name': 'Catalan', 'code': 'ca', 'longCode': 'ca-ES'}, {'name': 'Catalan (Valencian)', 'code': 'ca', 'longCode': 'ca-ES-valencia'}, {'name': 'Catalan (Balearic)', 'code': 'ca', 'longCode': 'ca-ES-balear'}, {'name': 'Danish', 'code': 'da', 'longCode': 'da-DK'}, {'name': 'German', 'code': 'de', 'longCode': 'de'}, {'name': 'German (Germany)', 'code': 'de', 'longCode': 'de-DE'}, {'name': 'German (Austria)', 'code': 'de', 'longCode': 'de-AT'}, {'name': 'German (Swiss)', 'code': 'de', 'longCode': 'de-CH'}, {'name': 'Simple German', 'code': 'de-DE-x-simple-language', 'longCode': 'de-DE-x-simple-language'}, {'name': 'Greek', 'code': 'el', 'longCode': 'el-GR'}, {'name': 'English', 'code': 'en', 'longCode': 'en'}, {'name': 'English (US)', 'code': 'en', 'longCode': 'en-U...\n",
      "Result:\n",
      " Yes\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: I think the API is being called to check the service status of the Luhn algorithm for validating card numbers. The current arguments are '{}' which means no additional parameters are provided. Maybe the assistant wants to determine if the API is operational before recommending it for use.\n",
      "Action: service_status_for_luhn_algorithm\n",
      "Action Input: {}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{\\\"service_status\\\":\\\"OK\\\"}\"}\n",
      "Result:\n",
      " Yes</s>\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: The service status of the card number validation API is currently \"OK\". I can proceed with recommending this API to validate card numbers.\n",
      "Action: validate_card_number_for_luhn_algorithm\n",
      "Action Input: {\n",
      "  \"number\": \"4111111111111111\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'card_number': '4111111111111111', 'is_valid': True, 'issuer_category': 'Banking and financial', 'issuing_network': 'Visa'}\"}\n",
      "Result:\n",
      " Yes</s>\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: To gather the required information for integrating APIs into the company's website, I can call the \"list_all_api_for_testing_for_my_use\" function. This function will provide me with descriptions, methods, required parameters, and optional parameters for each API. With this information, I can analyze and compare the APIs to make an informed decision.\n",
      "Action: list_all_api_for_testing_for_my_use\n",
      "Action Input: {}\n",
      "API Response:\n",
      "{\"error\": \"Unauthorized error...\", \"response\": \"{'1forge.com': {'added': '2017-05-30T08:34:14.000Z', 'preferred': '0.0.1', 'versions': {'0.0.1': {'added': '2017-05-30T08:34:14.000Z', 'info': {'contact': {'email': 'contact@1forge.com', 'name': '1Forge', 'url': 'http://1forge.com'}, 'description': 'Stock and Forex Data and Realtime Quotes', 'title': '1Forge Finance APIs', 'version': '0.0.1', 'x-apisguru-categories': ['financial'], 'x-logo': {'backgroundColor': '#24292e', 'url': 'https://api.apis.guru/v2/cache/logo/https_1forge.com_assets_images_f-blue.svg'}, 'x-origin': [{'format': 'swagger', 'url': 'http://1forge.com/openapi.json', 'version': '2.0'}], 'x-providerName': '1forge.com'}, 'updated': '2017-06-27T16:49:57.000Z', 'swaggerUrl': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1/swagger.json', 'swaggerYamlUrl': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1/swagger.yaml', 'openapiVer': '2.0', 'link': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1.json'}}}, '1password.com:events': {'added': '2021-07-19...\n",
      "Result:\n",
      " No\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: Based on the previous assistant message, I noticed that the \"list_all_api_for_testing_for_my_use\" function was called with no arguments. The purpose of this function call was to gather information about the APIs available for testing. By retrieving the descriptions, methods, required parameters, and optional parameters for each API, I can effectively analyze and compare them. This will enable me to make an informed decision regarding which APIs to integrate into the company's website. It seems like this function call was successful as it provided the necessary information.\n",
      "Action: metrics_for_testing_for_my_use\n",
      "Action Input: {}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'numSpecs': 3992, 'numAPIs': 2529, 'numEndpoints': 108837, 'unreachable': 166, 'invalid': 688, 'unofficial': 25, 'fixes': 84860, 'fixedPct': 23, 'datasets': [{'title': 'providerCount', 'data': {'adyen.com': 89, 'amadeus.com': 32, 'amazonaws.com': 286, 'apideck.com': 16, 'apisetu.gov.in': 181, 'azure.com': 1829, 'ebay.com': 20, 'fungenerators.com': 12, 'github.com': 21, 'googleapis.com': 464, 'hubapi.com': 12, 'interzoid.com': 20, 'mastercard.com': 14, 'microsoft.com': 27, 'nexmo.com': 20, 'nytimes.com': 11, 'parliament.uk': 11, 'sportsdata.io': 35, 'twilio.com': 44, 'vtex.local': 34, 'windows.net': 10, 'Others': 804}}], 'stars': 3151, 'issues': 35, 'thisWeek': {'added': 9, 'updated': 437}, 'numDrivers': 10, 'numProviders': 677}\"}\n",
      "Result:\n",
      " Yes</s>\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: To retrieve a list of popular movies available for playback in the US, I will call the 'movies_for_streamlinewatch_streaming_guide' function. This API will provide me with the necessary movie details, including the title, genres, overview, poster image, release date, vote average, and streaming sources. By limiting the number of records to 10, I can ensure that the movie marathon options are manageable for the company's employees.\n",
      "Action: movies_for_streamlinewatch_streaming_guide\n",
      "Action Input: {}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"[{'_id': 1102776, 'backdrop_path': '/zh614Bixv2ePaHK8gzcUpUmcvYv.jpg', 'genres': ['Thriller', 'Action & Adventure', 'Crime'], 'original_title': 'AKA', 'overview': \\\"A steely special ops agent finds his morality put to the test when he infiltrates a crime syndicate and unexpectedly bonds with the boss' young son.\\\", 'poster_path': '/3BSxAjiporlwQTWzaHZ9Yrl5C9D.jpg', 'release_date': '2023-04-28', 'title': 'AKA'}, {'_id': 948713, 'backdrop_path': '/xwA90BwZXTh8ke3CVsQlj8EOkFr.jpg', 'genres': ['Action & Adventure', 'Action & Adventure', 'History', 'Drama', 'War'], 'original_title': 'The Last Kingdom: Seven Kings Must Die', 'overview': \\\"In the wake of King Edward's death, Uhtred of Bebbanburg and his comrades adventure across a fractured kingdom in the hopes of uniting England at last.\\\", 'poster_path': '/7yyFEsuaLGTPul5UkHc5BhXnQ0k.jpg', 'release_date': '2023-04-14', 'title': 'The Last Kingdom: Seven Kings Must Die'}, {'_id': 638974, 'backdrop_path': '/bT3IpP7OopgiVuy6HCPOWLuaFAd.jpg',...\n",
      "Result:\n",
      "\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: The 'movies_for_streamlinewatch_streaming_guide' function was called to retrieve a list of popular movies available for playback in the US. By analyzing the movie details obtained from the API response, I can now proceed to gather the streaming sources for these movies by calling the 'sources_for_streamlinewatch_streaming_guide' function. To ensure the sources are for the US region, I will pass the argument 'region' with the value 'US' in the function call. This will help me provide accurate information to the company employees for their movie marathon.\n",
      "Action: sources_for_streamlinewatch_streaming_guide\n",
      "Action Input: {\n",
      "  \"region\": \"US\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"[{'source': 'showtime_anytime_tveverywhere', 'display_name': 'Showtime Anytime', 'type': 'tv_everywhere', 'info': 'http://www.showtimeanytime.com/', 'platform': {'android': 'https://play.google.com/store/apps/details?id=com.showtime.showtimeanytime', 'android_tv': 'com.showtime.showtimeanytime', 'ios': 'http://apps.apple.com/app/id484232467', 'web': 'http://www.showtimeanytime.com/'}}, {'source': 'hbo_max', 'display_name': 'HBO Max', 'type': 'subscription', 'info': 'http://www.hbomax.com', 'platform': {'android': 'https://play.google.com/store/apps/details?id=com.hbo.hbonow', 'android_tv': 'com.hbo.hbonow', 'ios': 'http://apps.apple.com/app/hbo-max-stream-tv-movies/id971265422', 'web': 'http://www.hbomax.com'}}, {'source': 'hulu', 'display_name': 'Hulu', 'type': 'subscription', 'info': 'http://www.hulu.com/', 'platform': {'android': 'https://play.google.com/store/apps/details?id=com.hulu.plus', 'android_tv': 'com.hulu.livingroomplus', 'ios': 'http://apps.apple.com/app/hulu-plus/id37...\n",
      "Result:\n",
      " Yes\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: I am calling the \"stock_splits_for_freedom_finance\" function because I need to retrieve information about stock splits for the symbol \"AMZN\". By providing the argument {\"symbol\": \"AMZN\"}, I can specifically target the stock \"AMZN\" and obtain its related data. This function will allow me to analyze the history of stock splits for \"AMZN\" and provide the user with the requested information.\n",
      "Action: stock_splits_for_freedom_finance\n",
      "Action Input: {\n",
      "\"symbol\": \"AMZN\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'total': 1, 'offset': 0, 'results': [{'date': '2022-06-06', 'before': 20, 'after': 1}], 'responseStatus': None}\"}\n",
      "Result:\n",
      " Yes</s>\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: I will now call the \"dividends_for_freedom_finance\" function to retrieve information about dividends for the symbol \"AMZN\". By using the argument {\"symbol\": \"AMZN\"}, I can focus specifically on the dividends related to the stock \"AMZN\". This function will help me analyze the dividend history for \"AMZN\" and provide the user with the requested information.\n",
      "Action: dividends_for_freedom_finance\n",
      "Action Input: {\n",
      "\"symbol\": \"AMZN\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'total': 0, 'offset': 0, 'results': [], 'responseStatus': None}\"}\n",
      "Result:\n",
      " No\n",
      "\n",
      "####################################################################################################\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data4/polyakov/instruction_tuning/ToolBench_pure_1/notebooks/llama_prompting_error_detection.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.198.127.135/data4/polyakov/instruction_tuning/ToolBench_pure_1/notebooks/llama_prompting_error_detection.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.198.127.135/data4/polyakov/instruction_tuning/ToolBench_pure_1/notebooks/llama_prompting_error_detection.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     tokenized \u001b[39m=\u001b[39m tokenizer(curr_prompt, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39minput_ids\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.198.127.135/data4/polyakov/instruction_tuning/ToolBench_pure_1/notebooks/llama_prompting_error_detection.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     res \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(tokenized, max_length\u001b[39m=\u001b[39;49mtokenized\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39m2\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.198.127.135/data4/polyakov/instruction_tuning/ToolBench_pure_1/notebooks/llama_prompting_error_detection.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAPI Call:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.198.127.135/data4/polyakov/instruction_tuning/ToolBench_pure_1/notebooks/llama_prompting_error_detection.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(item[\u001b[39m'\u001b[39m\u001b[39mconversations\u001b[39m\u001b[39m'\u001b[39m][i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/transformers/generation/utils.py:1606\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massisted_decoding(\n\u001b[1;32m   1590\u001b[0m         input_ids,\n\u001b[1;32m   1591\u001b[0m         assistant_model\u001b[39m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1603\u001b[0m     )\n\u001b[1;32m   1604\u001b[0m \u001b[39mif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1605\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1606\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1607\u001b[0m         input_ids,\n\u001b[1;32m   1608\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1609\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1610\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1611\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1612\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1613\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1614\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1615\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1616\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1617\u001b[0m     )\n\u001b[1;32m   1619\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1620\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/transformers/generation/utils.py:2454\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2453\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2454\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2455\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2456\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2457\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2458\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2459\u001b[0m )\n\u001b[1;32m   2461\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2462\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 166\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39;49m_hf_hook\u001b[39m.\u001b[39;49mpost_forward(module, output)\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/accelerate/hooks.py:305\u001b[0m, in \u001b[0;36mAlignDevicesHook.post_forward\u001b[0;34m(self, module, output)\u001b[0m\n\u001b[1;32m    302\u001b[0m             module\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mCxB \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mio_same_device \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 305\u001b[0m     output \u001b[39m=\u001b[39m send_to_device(output, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_device, skip_keys\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mskip_keys)\n\u001b[1;32m    307\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/accelerate/utils/operations.py:160\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[39melif\u001b[39;00m skip_keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m         skip_keys \u001b[39m=\u001b[39m []\n\u001b[1;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(tensor)(\n\u001b[0;32m--> 160\u001b[0m         {\n\u001b[1;32m    161\u001b[0m             k: t \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m skip_keys \u001b[39melse\u001b[39;00m send_to_device(t, device, non_blocking\u001b[39m=\u001b[39mnon_blocking, skip_keys\u001b[39m=\u001b[39mskip_keys)\n\u001b[1;32m    162\u001b[0m             \u001b[39mfor\u001b[39;00m k, t \u001b[39min\u001b[39;00m tensor\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    163\u001b[0m         }\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m\"\u001b[39m\u001b[39mto\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    166\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/accelerate/utils/operations.py:161\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[39melif\u001b[39;00m skip_keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m         skip_keys \u001b[39m=\u001b[39m []\n\u001b[1;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(tensor)(\n\u001b[1;32m    160\u001b[0m         {\n\u001b[0;32m--> 161\u001b[0m             k: t \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m skip_keys \u001b[39melse\u001b[39;00m send_to_device(t, device, non_blocking\u001b[39m=\u001b[39;49mnon_blocking, skip_keys\u001b[39m=\u001b[39;49mskip_keys)\n\u001b[1;32m    162\u001b[0m             \u001b[39mfor\u001b[39;00m k, t \u001b[39min\u001b[39;00m tensor\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    163\u001b[0m         }\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m\"\u001b[39m\u001b[39mto\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    166\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/accelerate/utils/operations.py:167\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m\"\u001b[39m\u001b[39mto\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    166\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m         \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49mto(device, non_blocking\u001b[39m=\u001b[39;49mnon_blocking)\n\u001b[1;32m    168\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for item in data[:10]:\n",
    "    flag = True\n",
    "    for i, step in enumerate(item['conversations']):\n",
    "        if step['from'] == 'function':\n",
    "            curr_prompt = prompt.replace('<api_call>', item['conversations'][i-1]['value'])\n",
    "            curr_prompt = curr_prompt.replace('<api_response>', step['value'])\n",
    "            with torch.no_grad():\n",
    "                tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "                res = model.generate(tokenized, max_length=tokenized.shape[1] + 2)\n",
    "                print('API Call:')\n",
    "                print(item['conversations'][i-1]['value'])\n",
    "                print('API Response:')\n",
    "                print(step['value'])\n",
    "                print('Result:')\n",
    "                print(tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0]))\n",
    "                print('#' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ,    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data4/polyakov/instruction_tuning/ToolBench_pure_1/data/self_correction/error_test_data/test_marked.txt', 'r') as f:\n",
    "    test_data = f.read()\n",
    "test_items = test_data.split('\\n###################################################################\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [06:04<00:00,  3.64s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for item in tqdm(test_items):\n",
    "    api_call = item.split('API Call: \\n')[1].split('\\nAPI Response')[0]\n",
    "    api_response = item.split('API Response:\\n')[1].split('\\nResult:')[0]\n",
    "    curr_prompt = prompt.replace('<api_call>', api_call)\n",
    "    curr_prompt = curr_prompt.replace('<api_response>', api_response)\n",
    "    with torch.no_grad():\n",
    "        tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "        res = model.generate(tokenized, max_length=tokenized.shape[1] + 1)\n",
    "        pred = tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0])\n",
    "        predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Yes': 77, 'No': 23})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for item in test_items:\n",
    "    ans = item.split('Result:\\n')[1].strip()\n",
    "    answers.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88, Precision: 0.974025974025974, Recall: 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tp = 0\n",
    "tn = 0\n",
    "for gt, pred in zip(answers, predictions):\n",
    "    if gt == pred:\n",
    "        acc += 1\n",
    "        if gt == 'No':\n",
    "            tn += 1\n",
    "        else:\n",
    "            tp += 1\n",
    "    elif gt == 'No' and pred == 'Yes':\n",
    "        fp += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "print(f'Accuracy: {acc}, Precision: {tp / (tp + fp)}, Recall: {tp / (tp + fn)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"Step 4: I'm looking for the external information of a device-asset identified by '71491234-A'. Could you assist me in retrieving the code, status, and message associated with this identifier? Additionally, please let me know if there are any optional parameters available.\\n\",\n",
       " 'api_call': 'Thought: I think the current API call is made to retrieve the information of a device-asset with the identifier \"71491234-A\". The reason for this call is to fulfill the user\\'s request to fetch the code, status, and message associated with the given identifier. The arguments for the API call specify the \"identifier\" parameter as \"71491234-A\". By providing this identifier, we can retrieve the desired device-asset information from the Vikkon platform.\\nAction: get_device_asset_by_identifier_copy_for_basic_info_vikkon_assets\\nAction Input: {\\n  \"identifier\": \"71491234-A\"\\n}\\n',\n",
       " 'api_response': '{\"error\": \"\", \"response\": \"{\\'code\\': \\'404 not found\\', \\'status\\': 404, \\'message\\': \\'Resource not found\\'}\"}\\n',\n",
       " 'label': 'No'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/data4/polyakov/instruction_tuning/ToolBench_pure_1/data/self_correction/error_test_data/final_test_balanced_marked.json', 'r') as f:\n",
    "    balanced_test = json.load(f)\n",
    "\n",
    "balanced_test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [01:23<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions_balanced_test = []\n",
    "for item in tqdm(balanced_test):\n",
    "    api_call = item['api_call']\n",
    "    api_response = item['api_response']\n",
    "    curr_prompt = prompt_zero_shot.replace('<api_call>', api_call)\n",
    "    curr_prompt = curr_prompt.replace('<api_response>', api_response)\n",
    "    with torch.no_grad():\n",
    "        tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "        res = model.generate(tokenized, max_length=tokenized.shape[1] + 1)\n",
    "        pred = tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0])\n",
    "        predictions_balanced_test.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_balanced_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81, Precision: 0.725, Recall: 0.7837837837837838\n"
     ]
    }
   ],
   "source": [
    "answers_balanced_test = [item['label'] for item in balanced_test]\n",
    "\n",
    "acc = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tp = 0\n",
    "tn = 0\n",
    "for gt, pred in zip(answers_balanced_test, predictions_balanced_test):\n",
    "    if gt == pred:\n",
    "        acc += 1\n",
    "        if gt == 'Yes':\n",
    "            tn += 1\n",
    "        else:\n",
    "            tp += 1\n",
    "    elif gt == 'Yes' and pred == 'No':\n",
    "        fp += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "print(f'Accuracy: {acc}, Precision: {tp / (tp + fp)}, Recall: {tp / (tp + fn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
