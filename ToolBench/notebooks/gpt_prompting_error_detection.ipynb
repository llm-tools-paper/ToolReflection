{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "import sys\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM, LlamaTokenizer\n",
    "import json\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key_path = '/data4/polyakov/GPT_KEY_MY_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = '/data4/polyakov/instruction_tuning/data/Llama-2-7b-chat-hf'\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#         base_model,\n",
    "#         load_in_4bit=True,\n",
    "#         local_files_only=True,\n",
    "#         device_map='auto',\n",
    "# )\n",
    "# model.config.use_cache = False\n",
    "# tokenizer = AutoTokenizer.from_pretrained(base_model, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gpt3_request(prompt: str):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant, useful for error detection.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "        stop=None,\n",
    "        )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gpt4_request(prompt: str):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant, useful for error detection.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "        stop=None,\n",
    "        )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmake_gpt3_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHi!\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m, in \u001b[0;36mmake_gpt3_request\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_gpt3_request\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful assistant, useful for error detection.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
     ]
    }
   ],
   "source": [
    "make_gpt3_request('Hi!')['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_gpt4_request('Hi!')['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_prompt = \"What does the fllowing sentence say? Translate to english. \\u6c7d\\u6c34\\u74f6\\u5851\\u6599\\u676f\\u900f\\u660e\\u78e8\\u7802\\u4fbf\\u643a\\u4e0d\\u6613\\u6454\\u7834\\u5bc6\\u5c01\\u540a\\u5e26\\u5976\\u8336\\u676f\\u6c34\\u676f\\u505a\\u793c\\u54c1 Translation:\"\n",
    "# tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "# res = model.generate(tokenized, max_length=tokenized.shape[1] + 2)\n",
    "# print(tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "You are you will be given api calls from some model and api outputs from rapidapi apis. \n",
    "Sometimes api return errors. \n",
    "It is hard to parse them using rule-based methods. \n",
    "An api may respond with an empty output (it could be empty list, or an empty dict), contain a field that states it is an error or etc.\n",
    "You will be given 5 examples. You should respond only \"Yes\" if the response does not contain errors from an api and \"No\" if not.\n",
    "Please make shure that api returned what the api call requested. If not, return \"No\"\n",
    "Examples:\n",
    "API Call:\n",
    "Thought: To fulfill the user's request for gathering user information and recent media posts from Instagram for a specific username 'nike', I previously called the 'userinfo_for_instagram_cheapest' function with the argument {\"username\": \"nike\"}. By doing so, I efficiently retrieved the desired user data, including their biography, bio links, biographical information, and other relevant details. Now, to proceed with accessing the user's recent media posts, I will call the 'user_medias_for_instagram_cheapest' function with the argument {\"user_id\": \"113294420064920\"}. This will allow me to retrieve the most recent media posts of the user 'nike' and provide the user with the requested data effectively.\n",
    "Action: user_medias_for_instagram_cheapest\n",
    "Action Input: {\n",
    "  \"user_id\": \"113294420064920\"\n",
    "}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"{'items': [], 'num_results': 0, 'status': 'ok'}\"}\n",
    "Result:\n",
    "No\n",
    "###\n",
    "API Call:\n",
    "Thought: The user requested the list of languages supported by the LanguageTool API for grammar and writing assistance. To fulfill this request, I need to call the \"list_of_languages_for_languagetool\" function without any arguments. By doing so, I expect to receive the complete list of supported languages. This information will be crucial for implementing multilingual support in the project, ensuring accurate grammar and writing assistance for different languages.\n",
    "Action: list_of_languages_for_languagetool\n",
    "Action Input: {}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"[{'name': 'Arabic', 'code': 'ar', 'longCode': 'ar'}, {'name': 'Asturian', 'code': 'ast', 'longCode': 'ast-ES'}, {'name': 'Belarusian', 'code': 'be', 'longCode': 'be-BY'}, {'name': 'Breton', 'code': 'br', 'longCode': 'br-FR'}, {'name': 'Catalan', 'code': 'ca', 'longCode': 'ca-ES'}, {'name': 'Catalan (Valencian)', 'code': 'ca', 'longCode': 'ca-ES-valencia'}, {'name': 'Catalan (Balearic)', 'code': 'ca', 'longCode': 'ca-ES-balear'}, {'name': 'Danish', 'code': 'da', 'longCode': 'da-DK'}, {'name': 'German', 'code': 'de', 'longCode': 'de'}, {'name': 'German (Germany)', 'code': 'de', 'longCode': 'de-DE'}, {'name': 'German (Austria)', 'code': 'de', 'longCode': 'de-AT'}, {'name': 'German (Swiss)', 'code': 'de', 'longCode': 'de-CH'}, {'name': 'Simple German', 'code': 'de-DE-x-simple-language', 'longCode': 'de-DE-x-simple-language'}, {'name': 'Greek', 'code': 'el', 'longCode': 'el-GR'}, {'name': 'English', 'code': 'en', 'longCode': 'en'}, {'name': 'English (US)', 'code': 'en', 'longCode': 'en-U..\n",
    "Result:\n",
    "Yes\n",
    "###\n",
    "API Call:\n",
    "Thought: I will now call the \"dividends_for_freedom_finance\" function to retrieve information about dividends for the symbol \"AMZN\". By using the argument {\"symbol\": \"AMZN\"}, I can focus specifically on the dividends related to the stock \"AMZN\". This function will help me analyze the dividend history for \"AMZN\" and provide the user with the requested information.\n",
    "Action: dividends_for_freedom_finance\n",
    "Action Input: {\n",
    "\"symbol\": \"AMZN\"\n",
    "}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"{'total': 0, 'offset': 0, 'results': [], 'responseStatus': None}\"}\n",
    "Result:\n",
    "No\n",
    "###\n",
    "API Call:\n",
    "Thought: To gather the required information for integrating APIs into the company's website, I can call the \"list_all_api_for_testing_for_my_use\" function. This function will provide me with descriptions, methods, required parameters, and optional parameters for each API. With this information, I can analyze and compare the APIs to make an informed decision.\n",
    "Action: list_all_api_for_testing_for_my_use\n",
    "Action Input: {}\n",
    "API Response:\n",
    "{\"error\": \"Unauthorized error...\", \"response\": \"{'1forge.com': {'added': '2017-05-30T08:34:14.000Z', 'preferred': '0.0.1', 'versions': {'0.0.1': {'added': '2017-05-30T08:34:14.000Z', 'info': {'contact': {'email': 'contact@1forge.com', 'name': '1Forge', 'url': 'http://1forge.com'}, 'description': 'Stock and Forex Data and Realtime Quotes', 'title': '1Forge Finance APIs', 'version': '0.0.1', 'x-apisguru-categories': ['financial'], 'x-logo': {'backgroundColor': '#24292e', 'url': 'https://api.apis.guru/v2/cache/logo/https_1forge.com_assets_images_f-blue.svg'}, 'x-origin': [{'format': 'swagger', 'url': 'http://1forge.com/openapi.json', 'version': '2.0'}], 'x-providerName': '1forge.com'}, 'updated': '2017-06-27T16:49:57.000Z', 'swaggerUrl': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1/swagger.json', 'swaggerYamlUrl': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1/swagger.yaml', 'openapiVer': '2.0', 'link': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1.json'}}}, '1password.com:events': {'added': '2021-07-19...\n",
    "Result:\n",
    "No\n",
    "###\n",
    "API Call:\n",
    "Thought: I need to gather user information for a specific Instagram username, 'nike', as requested by the user. They also want access to the user's recent media posts. To achieve this, I will call the 'userinfo_for_instagram_cheapest' function with the argument of {\"username\": \"nike\"}. This will help me retrieve the desired data efficiently and fulfill the user's request effectively.\n",
    "Action: userinfo_for_instagram_cheapest\n",
    "Action Input: {\n",
    "  \"username\": \"nike\"\n",
    "}\n",
    "API Response:\n",
    "{\"error\": \"\", \"response\": \"{'data': {'user': {'biography': 'Spotlighting athlete* and\\\\xa0\\ud83d\\udc5f\\\\xa0stories\\\\n#BlackLivesMatter, #StopAsianHate, and #NoPrideNoSport', 'bio_links': [{'title': '', 'lynx_url': 'https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fnike&e=AT063fG4N158ZbZOaZ_A32batiXwR-0Yih5XNa5wfSNPCiDo546PSV0a8mm72ElVxWgNJdgYeHNOTMMTOe_kn7R-C-f2N9ym', 'url': 'https://linkin.bio/nike', 'link_type': 'external'}], 'biography_with_entities': {'raw_text': 'Spotlighting athlete* and\\\\xa0\\ud83d\\udc5f\\\\xa0stories\\\\n#BlackLivesMatter, #StopAsianHate, and #NoPrideNoSport', 'entities': [{'user': None, 'hashtag': {'name': 'nopridenosport'}}, {'user': None, 'hashtag': {'name': 'stopasianhate'}}, {'user': None, 'hashtag': {'name': 'blacklivesmatter'}}]}, 'blocked_by_viewer': False, 'restricted_by_viewer': None, 'country_block': False, 'eimu_id': '113294420064920', 'external_url': 'https://linkin.bio/nike', 'external_url_linkshimmed': 'https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fnike&e=AT04S69...\n",
    "Result:\n",
    "Yes\n",
    "###\n",
    "API Call: \n",
    "<api_call>\n",
    "API Response:\n",
    "<api_response>\n",
    "Result:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_zero_shot = '''\n",
    "You are you will be api calls from some model and api outputs from rapidapi apis. \n",
    "Sometimes api return errors. \n",
    "It is hard to parse them using rule-based methods. \n",
    "An api may respond with an empty output (it could be empty list, or an empty dict), contain a field that states it is an error or etc.\n",
    "You will be given 5 examples. You should respond only \"Yes\" if the response does not contain errors from an api and \"No\" if not.\n",
    "Please make shure that api returned what the api call requested. If not, return \"No\"\n",
    "You will be given data in the folllowing format.\n",
    "API Call: \n",
    "api_call\n",
    "API Response:\n",
    "api_response\n",
    "Result: \n",
    "Yes/No\n",
    "Begin!\n",
    "###\n",
    "API Call: \n",
    "<api_call>\n",
    "API Response:\n",
    "<api_response>\n",
    "Result:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('/data4/polyakov/instruction_tuning/ToolBench/data/toolbench_new_1311/cleaned_toolllama_G123_dfs_train_downloaded1311_no_this_is_not_the_first_time_you_tried.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Call:\n",
      "\n",
      "Thought: I need to gather user information for a specific Instagram username, 'nike', as requested by the user. They also want access to the user's recent media posts. To achieve this, I will call the 'userinfo_for_instagram_cheapest' function with the argument of {\"username\": \"nike\"}. This will help me retrieve the desired data efficiently and fulfill the user's request effectively.\n",
      "Action: userinfo_for_instagram_cheapest\n",
      "Action Input: {\n",
      "  \"username\": \"nike\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'data': {'user': {'biography': 'Spotlighting athlete* and\\\\xa0\\ud83d\\udc5f\\\\xa0stories\\\\n#BlackLivesMatter, #StopAsianHate, and #NoPrideNoSport', 'bio_links': [{'title': '', 'lynx_url': 'https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fnike&e=AT063fG4N158ZbZOaZ_A32batiXwR-0Yih5XNa5wfSNPCiDo546PSV0a8mm72ElVxWgNJdgYeHNOTMMTOe_kn7R-C-f2N9ym', 'url': 'https://linkin.bio/nike', 'link_type': 'external'}], 'biography_with_entities': {'raw_text': 'Spotlighting athlete* and\\\\xa0\\ud83d\\udc5f\\\\xa0stories\\\\n#BlackLivesMatter, #StopAsianHate, and #NoPrideNoSport', 'entities': [{'user': None, 'hashtag': {'name': 'nopridenosport'}}, {'user': None, 'hashtag': {'name': 'stopasianhate'}}, {'user': None, 'hashtag': {'name': 'blacklivesmatter'}}]}, 'blocked_by_viewer': False, 'restricted_by_viewer': None, 'country_block': False, 'eimu_id': '113294420064920', 'external_url': 'https://linkin.bio/nike', 'external_url_linkshimmed': 'https://l.instagram.com/?u=https%3A%2F%2Flinkin.bio%2Fnike&e=AT04S69...\n",
      "Result:\n",
      " Yes\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: To fulfill the user's request for gathering user information and recent media posts from Instagram for a specific username 'nike', I previously called the 'userinfo_for_instagram_cheapest' function with the argument {\"username\": \"nike\"}. By doing so, I efficiently retrieved the desired user data, including their biography, bio links, biographical information, and other relevant details. Now, to proceed with accessing the user's recent media posts, I will call the 'user_medias_for_instagram_cheapest' function with the argument {\"user_id\": \"113294420064920\"}. This will allow me to retrieve the most recent media posts of the user 'nike' and provide the user with the requested data effectively.\n",
      "Action: user_medias_for_instagram_cheapest\n",
      "Action Input: {\n",
      "  \"user_id\": \"113294420064920\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'items': [], 'num_results': 0, 'status': 'ok'}\"}\n",
      "Result:\n",
      " No\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: I am calling the Chuck Norris API to generate a random joke about Chuck Norris in response to the user's request. This will provide an amusing and entertaining response for the user.\n",
      "Action: jokes_random_for_chuck_norris\n",
      "Action Input: {}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{\\\"categories\\\":[],\\\"created_at\\\":\\\"2020-01-05 13:42:28.143137\\\",\\\"icon_url\\\":\\\"https://assets.chucknorris.host/img/avatar/chuck-norris.png\\\",\\\"id\\\":\\\"w1QcOOGdStm9Wz27-AKCIw\\\",\\\"updated_at\\\":\\\"2020-01-05 13:42:28.143137\\\",\\\"url\\\":\\\"https://api.chucknorris.io/jokes/w1QcOOGdStm9Wz27-AKCIw\\\",\\\"value\\\":\\\"Chuck Norris doesn't clip his fingernails... he rips them out with his bare hands and regrows new ones immediately.\\\"}\"}\n",
      "Result:\n",
      " Yes</s>\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: I am calling the 'get_math_fact_for_numbers' API with the argument {'number': '1729'}. This API call is made to provide the user with a fascinating mathematical property about the number 1729. By retrieving this information, I can fulfill the user's request for an interesting fact about the number.\n",
      "Action: get_math_fact_for_numbers\n",
      "Action Input: {\n",
      "  \"number\": \"1729\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'text': 'the smallest natural number representable in two different ways as a sum of two positive cubes, as Ramanujan stated on the spot', 'number': 1729, 'found': True, 'type': 'math'}\"}\n",
      "Result:\n",
      " Yes</s>\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: To fetch the list of languages supported by the Microsoft Translator Text API, I called the \"languages_for_microsoft_translator_text\" function with the argument \"api_version\" set to \"3.0\". The reason for this API call is that the user requested the list of languages supported by this API. By providing the \"api_version\" argument, I ensured that I am accessing the latest version of the API. This will help me gather the necessary information to support multilingual functionality in the project.\n",
      "Action: languages_for_microsoft_translator_text\n",
      "Action Input: {\n",
      "  \"api_version\": \"3.0\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"\\u001f\\ufffd\\b\\u0000\\u0000\\u0000\\u0000\\u0000\\u0004\\u0000\\ufffd][o\\u001bG\\ufffd\\ufffd+\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\u0007\\ufffd-\\ufffd\\ufffd\\ufffd\\ufffdK<\\ufffd\\ufffd\\ufffd\\ufffdE\\u001e\\ufffdb\\ufffdl\\ufffd\\ufffd-\\ufffdE\\u001a*0 Y\\u001e\\u0271\\ufffd\\u001d;\\u0019K\\ufffdmX\\ufffd\\ufffd\\u000b\\ufffd\\ufffdBQ\\ufffd%K\\ufffd\\ufffd@\\ufffda\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdR\\f\\u0018E$cg&\\ufffd\\ufffda\\ufffd\\ufffdl\\ufffd\\ufffdO5\\ufffd\\ufffd\\u0005\\u0006v\\u0010\\ufffd\\ufffd\\ufffdy\\ufffd\\ufffd\\ua72aS\\ufffdTWW}\\u06a2\\ufffdH\\ufffd$\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdO[P\\ufffd\\ufffd)\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdU1\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdH\\u0017\\ufffd\\ufffd\\ufffd\\ufffdBBTI\\ufffd\\ufffd\\ufffd-\\ufffd\\ufffd\\ufffd\\ufffd\\f-\\ufffdI!U\\ufffdr\\nW\\ufffdOU\\ufffd\\u076b\\\\[\\ufffd\\\\\\ufffd\\u0007\\ufffdUZ^Eq(~0\\u007fx\\ufffd\\ufffd\\ufffd\\ufffd\\ufffdA\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd:\\ufffd\\ufffdK\\u0016\\ufffdF\\u0003h\\u001a\\ufffd\\ufffd\\tN\\b<\\ufffd{<\\ufffd\\ufffd\\ufffd\\ufffd\\ufffd \\ufffd[\\ufffdsO\\ufffd\\ufffd\\u001e\\ufffd2@#\\...\n",
      "Result:\n",
      " No\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: I called the \"ages_by_this_api_endpoint_for_simple_elegant_translation_service\" function without any arguments. This API call is made to fetch the list of languages supported by the Simple & Elegant Translation Service API. By not providing any arguments, I expect to receive the complete list of supported languages. This information will be helpful for implementing multilingual support in the project.\n",
      "Action: ages_by_this_api_endpoint_for_simple_elegant_translation_service\n",
      "Action Input: {}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'languages': {'af': 'afrikaans', 'am': 'amharic', 'ar': 'arabic', 'az': 'azerbaijani', 'be': 'belarusian', 'bg': 'bulgarian', 'bn': 'bengali', 'bs': 'bosnian', 'ca': 'catalan', 'ceb': 'cebuano', 'co': 'corsican', 'cs': 'czech', 'cy': 'welsh', 'da': 'danish', 'de': 'german', 'el': 'greek', 'en': 'english', 'eo': 'esperanto', 'es': 'spanish', 'et': 'estonian', 'eu': 'basque', 'fa': 'persian', 'fi': 'finnish', 'fil': 'Filipino', 'fr': 'french', 'fy': 'frisian', 'ga': 'irish', 'gd': 'scots gaelic', 'gl': 'galician', 'gu': 'gujarati', 'ha': 'hausa', 'haw': 'hawaiian', 'he': 'Hebrew', 'hi': 'hindi', 'hmn': 'hmong', 'hr': 'croatian', 'ht': 'haitian creole', 'hu': 'hungarian', 'hy': 'armenian', 'id': 'indonesian', 'ig': 'igbo', 'is': 'icelandic', 'it': 'italian', 'iw': 'hebrew', 'ja': 'japanese', 'jw': 'javanese', 'ka': 'georgian', 'kk': 'kazakh', 'km': 'khmer', 'kn': 'kannada', 'ko': 'korean', 'ku': 'kurdish (kurmanji)', 'ky': 'kyrgyz', 'la': 'latin', 'lb': 'luxembourgish', 'lo': 'lao', '...\n",
      "Result:\n",
      " Yes\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: The user requested the list of languages supported by the LanguageTool API for grammar and writing assistance. To fulfill this request, I need to call the \"list_of_languages_for_languagetool\" function without any arguments. By doing so, I expect to receive the complete list of supported languages. This information will be crucial for implementing multilingual support in the project, ensuring accurate grammar and writing assistance for different languages.\n",
      "Action: list_of_languages_for_languagetool\n",
      "Action Input: {}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"[{'name': 'Arabic', 'code': 'ar', 'longCode': 'ar'}, {'name': 'Asturian', 'code': 'ast', 'longCode': 'ast-ES'}, {'name': 'Belarusian', 'code': 'be', 'longCode': 'be-BY'}, {'name': 'Breton', 'code': 'br', 'longCode': 'br-FR'}, {'name': 'Catalan', 'code': 'ca', 'longCode': 'ca-ES'}, {'name': 'Catalan (Valencian)', 'code': 'ca', 'longCode': 'ca-ES-valencia'}, {'name': 'Catalan (Balearic)', 'code': 'ca', 'longCode': 'ca-ES-balear'}, {'name': 'Danish', 'code': 'da', 'longCode': 'da-DK'}, {'name': 'German', 'code': 'de', 'longCode': 'de'}, {'name': 'German (Germany)', 'code': 'de', 'longCode': 'de-DE'}, {'name': 'German (Austria)', 'code': 'de', 'longCode': 'de-AT'}, {'name': 'German (Swiss)', 'code': 'de', 'longCode': 'de-CH'}, {'name': 'Simple German', 'code': 'de-DE-x-simple-language', 'longCode': 'de-DE-x-simple-language'}, {'name': 'Greek', 'code': 'el', 'longCode': 'el-GR'}, {'name': 'English', 'code': 'en', 'longCode': 'en'}, {'name': 'English (US)', 'code': 'en', 'longCode': 'en-U...\n",
      "Result:\n",
      " Yes\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: I think the API is being called to check the service status of the Luhn algorithm for validating card numbers. The current arguments are '{}' which means no additional parameters are provided. Maybe the assistant wants to determine if the API is operational before recommending it for use.\n",
      "Action: service_status_for_luhn_algorithm\n",
      "Action Input: {}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{\\\"service_status\\\":\\\"OK\\\"}\"}\n",
      "Result:\n",
      " Yes</s>\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: The service status of the card number validation API is currently \"OK\". I can proceed with recommending this API to validate card numbers.\n",
      "Action: validate_card_number_for_luhn_algorithm\n",
      "Action Input: {\n",
      "  \"number\": \"4111111111111111\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'card_number': '4111111111111111', 'is_valid': True, 'issuer_category': 'Banking and financial', 'issuing_network': 'Visa'}\"}\n",
      "Result:\n",
      " Yes</s>\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: To gather the required information for integrating APIs into the company's website, I can call the \"list_all_api_for_testing_for_my_use\" function. This function will provide me with descriptions, methods, required parameters, and optional parameters for each API. With this information, I can analyze and compare the APIs to make an informed decision.\n",
      "Action: list_all_api_for_testing_for_my_use\n",
      "Action Input: {}\n",
      "API Response:\n",
      "{\"error\": \"Unauthorized error...\", \"response\": \"{'1forge.com': {'added': '2017-05-30T08:34:14.000Z', 'preferred': '0.0.1', 'versions': {'0.0.1': {'added': '2017-05-30T08:34:14.000Z', 'info': {'contact': {'email': 'contact@1forge.com', 'name': '1Forge', 'url': 'http://1forge.com'}, 'description': 'Stock and Forex Data and Realtime Quotes', 'title': '1Forge Finance APIs', 'version': '0.0.1', 'x-apisguru-categories': ['financial'], 'x-logo': {'backgroundColor': '#24292e', 'url': 'https://api.apis.guru/v2/cache/logo/https_1forge.com_assets_images_f-blue.svg'}, 'x-origin': [{'format': 'swagger', 'url': 'http://1forge.com/openapi.json', 'version': '2.0'}], 'x-providerName': '1forge.com'}, 'updated': '2017-06-27T16:49:57.000Z', 'swaggerUrl': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1/swagger.json', 'swaggerYamlUrl': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1/swagger.yaml', 'openapiVer': '2.0', 'link': 'https://api.apis.guru/v2/specs/1forge.com/0.0.1.json'}}}, '1password.com:events': {'added': '2021-07-19...\n",
      "Result:\n",
      " No\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: Based on the previous assistant message, I noticed that the \"list_all_api_for_testing_for_my_use\" function was called with no arguments. The purpose of this function call was to gather information about the APIs available for testing. By retrieving the descriptions, methods, required parameters, and optional parameters for each API, I can effectively analyze and compare them. This will enable me to make an informed decision regarding which APIs to integrate into the company's website. It seems like this function call was successful as it provided the necessary information.\n",
      "Action: metrics_for_testing_for_my_use\n",
      "Action Input: {}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'numSpecs': 3992, 'numAPIs': 2529, 'numEndpoints': 108837, 'unreachable': 166, 'invalid': 688, 'unofficial': 25, 'fixes': 84860, 'fixedPct': 23, 'datasets': [{'title': 'providerCount', 'data': {'adyen.com': 89, 'amadeus.com': 32, 'amazonaws.com': 286, 'apideck.com': 16, 'apisetu.gov.in': 181, 'azure.com': 1829, 'ebay.com': 20, 'fungenerators.com': 12, 'github.com': 21, 'googleapis.com': 464, 'hubapi.com': 12, 'interzoid.com': 20, 'mastercard.com': 14, 'microsoft.com': 27, 'nexmo.com': 20, 'nytimes.com': 11, 'parliament.uk': 11, 'sportsdata.io': 35, 'twilio.com': 44, 'vtex.local': 34, 'windows.net': 10, 'Others': 804}}], 'stars': 3151, 'issues': 35, 'thisWeek': {'added': 9, 'updated': 437}, 'numDrivers': 10, 'numProviders': 677}\"}\n",
      "Result:\n",
      " Yes</s>\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: To retrieve a list of popular movies available for playback in the US, I will call the 'movies_for_streamlinewatch_streaming_guide' function. This API will provide me with the necessary movie details, including the title, genres, overview, poster image, release date, vote average, and streaming sources. By limiting the number of records to 10, I can ensure that the movie marathon options are manageable for the company's employees.\n",
      "Action: movies_for_streamlinewatch_streaming_guide\n",
      "Action Input: {}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"[{'_id': 1102776, 'backdrop_path': '/zh614Bixv2ePaHK8gzcUpUmcvYv.jpg', 'genres': ['Thriller', 'Action & Adventure', 'Crime'], 'original_title': 'AKA', 'overview': \\\"A steely special ops agent finds his morality put to the test when he infiltrates a crime syndicate and unexpectedly bonds with the boss' young son.\\\", 'poster_path': '/3BSxAjiporlwQTWzaHZ9Yrl5C9D.jpg', 'release_date': '2023-04-28', 'title': 'AKA'}, {'_id': 948713, 'backdrop_path': '/xwA90BwZXTh8ke3CVsQlj8EOkFr.jpg', 'genres': ['Action & Adventure', 'Action & Adventure', 'History', 'Drama', 'War'], 'original_title': 'The Last Kingdom: Seven Kings Must Die', 'overview': \\\"In the wake of King Edward's death, Uhtred of Bebbanburg and his comrades adventure across a fractured kingdom in the hopes of uniting England at last.\\\", 'poster_path': '/7yyFEsuaLGTPul5UkHc5BhXnQ0k.jpg', 'release_date': '2023-04-14', 'title': 'The Last Kingdom: Seven Kings Must Die'}, {'_id': 638974, 'backdrop_path': '/bT3IpP7OopgiVuy6HCPOWLuaFAd.jpg',...\n",
      "Result:\n",
      "\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: The 'movies_for_streamlinewatch_streaming_guide' function was called to retrieve a list of popular movies available for playback in the US. By analyzing the movie details obtained from the API response, I can now proceed to gather the streaming sources for these movies by calling the 'sources_for_streamlinewatch_streaming_guide' function. To ensure the sources are for the US region, I will pass the argument 'region' with the value 'US' in the function call. This will help me provide accurate information to the company employees for their movie marathon.\n",
      "Action: sources_for_streamlinewatch_streaming_guide\n",
      "Action Input: {\n",
      "  \"region\": \"US\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"[{'source': 'showtime_anytime_tveverywhere', 'display_name': 'Showtime Anytime', 'type': 'tv_everywhere', 'info': 'http://www.showtimeanytime.com/', 'platform': {'android': 'https://play.google.com/store/apps/details?id=com.showtime.showtimeanytime', 'android_tv': 'com.showtime.showtimeanytime', 'ios': 'http://apps.apple.com/app/id484232467', 'web': 'http://www.showtimeanytime.com/'}}, {'source': 'hbo_max', 'display_name': 'HBO Max', 'type': 'subscription', 'info': 'http://www.hbomax.com', 'platform': {'android': 'https://play.google.com/store/apps/details?id=com.hbo.hbonow', 'android_tv': 'com.hbo.hbonow', 'ios': 'http://apps.apple.com/app/hbo-max-stream-tv-movies/id971265422', 'web': 'http://www.hbomax.com'}}, {'source': 'hulu', 'display_name': 'Hulu', 'type': 'subscription', 'info': 'http://www.hulu.com/', 'platform': {'android': 'https://play.google.com/store/apps/details?id=com.hulu.plus', 'android_tv': 'com.hulu.livingroomplus', 'ios': 'http://apps.apple.com/app/hulu-plus/id37...\n",
      "Result:\n",
      " Yes\n",
      "\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: I am calling the \"stock_splits_for_freedom_finance\" function because I need to retrieve information about stock splits for the symbol \"AMZN\". By providing the argument {\"symbol\": \"AMZN\"}, I can specifically target the stock \"AMZN\" and obtain its related data. This function will allow me to analyze the history of stock splits for \"AMZN\" and provide the user with the requested information.\n",
      "Action: stock_splits_for_freedom_finance\n",
      "Action Input: {\n",
      "\"symbol\": \"AMZN\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'total': 1, 'offset': 0, 'results': [{'date': '2022-06-06', 'before': 20, 'after': 1}], 'responseStatus': None}\"}\n",
      "Result:\n",
      " Yes</s>\n",
      "####################################################################################################\n",
      "API Call:\n",
      "\n",
      "Thought: I will now call the \"dividends_for_freedom_finance\" function to retrieve information about dividends for the symbol \"AMZN\". By using the argument {\"symbol\": \"AMZN\"}, I can focus specifically on the dividends related to the stock \"AMZN\". This function will help me analyze the dividend history for \"AMZN\" and provide the user with the requested information.\n",
      "Action: dividends_for_freedom_finance\n",
      "Action Input: {\n",
      "\"symbol\": \"AMZN\"\n",
      "}\n",
      "API Response:\n",
      "{\"error\": \"\", \"response\": \"{'total': 0, 'offset': 0, 'results': [], 'responseStatus': None}\"}\n",
      "Result:\n",
      " No\n",
      "\n",
      "####################################################################################################\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data4/polyakov/instruction_tuning/ToolBench_pure_1/notebooks/llama_prompting_error_detection.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.198.127.135/data4/polyakov/instruction_tuning/ToolBench_pure_1/notebooks/llama_prompting_error_detection.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.198.127.135/data4/polyakov/instruction_tuning/ToolBench_pure_1/notebooks/llama_prompting_error_detection.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     tokenized \u001b[39m=\u001b[39m tokenizer(curr_prompt, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39minput_ids\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.198.127.135/data4/polyakov/instruction_tuning/ToolBench_pure_1/notebooks/llama_prompting_error_detection.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     res \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(tokenized, max_length\u001b[39m=\u001b[39;49mtokenized\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39m2\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.198.127.135/data4/polyakov/instruction_tuning/ToolBench_pure_1/notebooks/llama_prompting_error_detection.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAPI Call:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.198.127.135/data4/polyakov/instruction_tuning/ToolBench_pure_1/notebooks/llama_prompting_error_detection.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(item[\u001b[39m'\u001b[39m\u001b[39mconversations\u001b[39m\u001b[39m'\u001b[39m][i\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/transformers/generation/utils.py:1606\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massisted_decoding(\n\u001b[1;32m   1590\u001b[0m         input_ids,\n\u001b[1;32m   1591\u001b[0m         assistant_model\u001b[39m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1603\u001b[0m     )\n\u001b[1;32m   1604\u001b[0m \u001b[39mif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1605\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1606\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgreedy_search(\n\u001b[1;32m   1607\u001b[0m         input_ids,\n\u001b[1;32m   1608\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1609\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1610\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1611\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1612\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1613\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1614\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1615\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1616\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1617\u001b[0m     )\n\u001b[1;32m   1619\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1620\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/transformers/generation/utils.py:2454\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2453\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2454\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2455\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2456\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2457\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2458\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2459\u001b[0m )\n\u001b[1;32m   2461\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2462\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     output \u001b[39m=\u001b[39m old_forward(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 166\u001b[0m \u001b[39mreturn\u001b[39;00m module\u001b[39m.\u001b[39;49m_hf_hook\u001b[39m.\u001b[39;49mpost_forward(module, output)\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/accelerate/hooks.py:305\u001b[0m, in \u001b[0;36mAlignDevicesHook.post_forward\u001b[0;34m(self, module, output)\u001b[0m\n\u001b[1;32m    302\u001b[0m             module\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mCxB \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mio_same_device \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_device \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 305\u001b[0m     output \u001b[39m=\u001b[39m send_to_device(output, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_device, skip_keys\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mskip_keys)\n\u001b[1;32m    307\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/accelerate/utils/operations.py:160\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[39melif\u001b[39;00m skip_keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m         skip_keys \u001b[39m=\u001b[39m []\n\u001b[1;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(tensor)(\n\u001b[0;32m--> 160\u001b[0m         {\n\u001b[1;32m    161\u001b[0m             k: t \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m skip_keys \u001b[39melse\u001b[39;00m send_to_device(t, device, non_blocking\u001b[39m=\u001b[39mnon_blocking, skip_keys\u001b[39m=\u001b[39mskip_keys)\n\u001b[1;32m    162\u001b[0m             \u001b[39mfor\u001b[39;00m k, t \u001b[39min\u001b[39;00m tensor\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    163\u001b[0m         }\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m\"\u001b[39m\u001b[39mto\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    166\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/accelerate/utils/operations.py:161\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[39melif\u001b[39;00m skip_keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m         skip_keys \u001b[39m=\u001b[39m []\n\u001b[1;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(tensor)(\n\u001b[1;32m    160\u001b[0m         {\n\u001b[0;32m--> 161\u001b[0m             k: t \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m skip_keys \u001b[39melse\u001b[39;00m send_to_device(t, device, non_blocking\u001b[39m=\u001b[39;49mnon_blocking, skip_keys\u001b[39m=\u001b[39;49mskip_keys)\n\u001b[1;32m    162\u001b[0m             \u001b[39mfor\u001b[39;00m k, t \u001b[39min\u001b[39;00m tensor\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    163\u001b[0m         }\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m\"\u001b[39m\u001b[39mto\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    166\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/accelerate/utils/operations.py:167\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m\"\u001b[39m\u001b[39mto\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    166\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m         \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49mto(device, non_blocking\u001b[39m=\u001b[39;49mnon_blocking)\n\u001b[1;32m    168\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for item in data[:10]:\n",
    "    flag = True\n",
    "    for i, step in enumerate(item['conversations']):\n",
    "        if step['from'] == 'function':\n",
    "            curr_prompt = prompt.replace('<api_call>', item['conversations'][i-1]['value'])\n",
    "            curr_prompt = curr_prompt.replace('<api_response>', step['value'])\n",
    "            with torch.no_grad():\n",
    "                tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "                res = model.generate(tokenized, max_length=tokenized.shape[1] + 2)\n",
    "                print('API Call:')\n",
    "                print(item['conversations'][i-1]['value'])\n",
    "                print('API Response:')\n",
    "                print(step['value'])\n",
    "                print('Result:')\n",
    "                print(tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0]))\n",
    "                print('#' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ,    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data4/polyakov/instruction_tuning/ToolBench_pure_1/data/self_correction/error_test_data/test_marked.txt', 'r') as f:\n",
    "    test_data = f.read()\n",
    "test_items = test_data.split('\\n###################################################################\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# for item in tqdm(test_items):\n",
    "#     api_call = item.split('API Call: \\n')[1].split('\\nAPI Response')[0]\n",
    "#     api_response = item.split('API Response:\\n')[1].split('\\nResult:')[0]\n",
    "#     curr_prompt = prompt.replace('<api_call>', api_call)\n",
    "#     curr_prompt = curr_prompt.replace('<api_response>', api_response)\n",
    "#     with torch.no_grad():\n",
    "#         tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "#         res = model.generate(tokenized, max_length=tokenized.shape[1] + 1)\n",
    "#         pred = tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0])\n",
    "#         predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                              | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m curr_prompt \u001b[38;5;241m=\u001b[39m curr_prompt\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<api_response>\u001b[39m\u001b[38;5;124m'\u001b[39m, api_response)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 8\u001b[0m     tokenized \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(curr_prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[1;32m      9\u001b[0m     res \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(tokenized, max_length\u001b[38;5;241m=\u001b[39mtokenized\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m     pred \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(res)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mremoveprefix(tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(tokenized)[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for item in tqdm(test_items):\n",
    "    api_call = item.split('API Call: \\n')[1].split('\\nAPI Response')[0]\n",
    "    api_response = item.split('API Response:\\n')[1].split('\\nResult:')[0]\n",
    "    curr_prompt = prompt.replace('<api_call>', api_call)\n",
    "    curr_prompt = curr_prompt.replace('<api_response>', api_response)\n",
    "    with torch.no_grad():\n",
    "        tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "        res = model.generate(tokenized, max_length=tokenized.shape[1] + 1)\n",
    "        pred = tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0])\n",
    "        predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Yes': 77, 'No': 23})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for item in test_items:\n",
    "    ans = item.split('Result:\\n')[1].strip()\n",
    "    answers.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88, Precision: 0.974025974025974, Recall: 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tp = 0\n",
    "tn = 0\n",
    "for gt, pred in zip(answers, predictions):\n",
    "    if gt == pred:\n",
    "        acc += 1\n",
    "        if gt == 'No':\n",
    "            tn += 1\n",
    "        else:\n",
    "            tp += 1\n",
    "    elif gt == 'No' and pred == 'Yes':\n",
    "        fp += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "print(f'Accuracy: {acc}, Precision: {tp / (tp + fp)}, Recall: {tp / (tp + fn)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"Step 4: I'm looking for the external information of a device-asset identified by '71491234-A'. Could you assist me in retrieving the code, status, and message associated with this identifier? Additionally, please let me know if there are any optional parameters available.\\n\",\n",
       " 'api_call': 'Thought: I think the current API call is made to retrieve the information of a device-asset with the identifier \"71491234-A\". The reason for this call is to fulfill the user\\'s request to fetch the code, status, and message associated with the given identifier. The arguments for the API call specify the \"identifier\" parameter as \"71491234-A\". By providing this identifier, we can retrieve the desired device-asset information from the Vikkon platform.\\nAction: get_device_asset_by_identifier_copy_for_basic_info_vikkon_assets\\nAction Input: {\\n  \"identifier\": \"71491234-A\"\\n}\\n',\n",
       " 'api_response': '{\"error\": \"\", \"response\": \"{\\'code\\': \\'404 not found\\', \\'status\\': 404, \\'message\\': \\'Resource not found\\'}\"}\\n',\n",
       " 'label': 'No'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/data4/polyakov/instruction_tuning/ToolBench_pure_1/data/self_correction/error_test_data/final_test_balanced_marked.json', 'r') as f:\n",
    "    balanced_test = json.load(f)\n",
    "\n",
    "balanced_test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_balanced_test = []\n",
    "# for item in tqdm(balanced_test):\n",
    "#     api_call = item['api_call']\n",
    "#     api_response = item['api_response']\n",
    "#     curr_prompt = prompt_zero_shot.replace('<api_call>', api_call)\n",
    "#     curr_prompt = curr_prompt.replace('<api_response>', api_response)\n",
    "#     with torch.no_grad():\n",
    "#         tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "#         res = model.generate(tokenized, max_length=tokenized.shape[1] + 1)\n",
    "#         pred = tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0])\n",
    "#         predictions_balanced_test.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                              | 0/100 [00:00<?, ?it/s]\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/jupyter_client/session.py\", line 95, in json_packer\n",
      "    return json.dumps(\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 5851-5852: surrogates not allowed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 584, in _run_callback\n",
      "    f = callback(*args, **kwargs)\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/ipykernel/iostream.py\", line 120, in _handle_event\n",
      "    event_f()\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/ipykernel/iostream.py\", line 510, in _flush\n",
      "    self.session.send(\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/jupyter_client/session.py\", line 850, in send\n",
      "    to_send = self.serialize(msg, ident)\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/jupyter_client/session.py\", line 719, in serialize\n",
      "    content = self.pack(content)\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/jupyter_client/session.py\", line 103, in json_packer\n",
      "    packed = json.dumps(\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 5851-5852: surrogates not allowed\n",
      "ERROR:tornado.general:Uncaught exception in zmqstream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/jupyter_client/session.py\", line 95, in json_packer\n",
      "    return json.dumps(\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 5851-5852: surrogates not allowed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 634, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 663, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 584, in _run_callback\n",
      "    f = callback(*args, **kwargs)\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/ipykernel/iostream.py\", line 120, in _handle_event\n",
      "    event_f()\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/ipykernel/iostream.py\", line 510, in _flush\n",
      "    self.session.send(\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/jupyter_client/session.py\", line 850, in send\n",
      "    to_send = self.serialize(msg, ident)\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/jupyter_client/session.py\", line 719, in serialize\n",
      "    content = self.pack(content)\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/jupyter_client/session.py\", line 103, in json_packer\n",
      "    packed = json.dumps(\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 5851-5852: surrogates not allowed\n",
      "ERROR:tornado.application:Exception in callback functools.partial(<function ZMQStream._update_handler.<locals>.<lambda> at 0x7f95da0d1ab0>)\n",
      "Traceback (most recent call last):\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/jupyter_client/session.py\", line 95, in json_packer\n",
      "    return json.dumps(\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 5851-5852: surrogates not allowed\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/tornado/ioloop.py\", line 740, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 718, in <lambda>\n",
      "    self.io_loop.add_callback(lambda: self._handle_events(self.socket, 0))\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 634, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 663, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/zmq/eventloop/zmqstream.py\", line 584, in _run_callback\n",
      "    f = callback(*args, **kwargs)\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/ipykernel/iostream.py\", line 120, in _handle_event\n",
      "    event_f()\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/ipykernel/iostream.py\", line 510, in _flush\n",
      "    self.session.send(\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/jupyter_client/session.py\", line 850, in send\n",
      "    to_send = self.serialize(msg, ident)\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/jupyter_client/session.py\", line 719, in serialize\n",
      "    content = self.pack(content)\n",
      "  File \"/data2/polyakov/anaconda3/envs/alpaca-lora/lib/python3.10/site-packages/jupyter_client/session.py\", line 103, in json_packer\n",
      "    packed = json.dumps(\n",
      "UnicodeEncodeError: 'utf-8' codec can't encode characters in position 5851-5852: surrogates not allowed\n",
      "IOStream.flush timed out\n"
     ]
    }
   ],
   "source": [
    "predictions_balanced_test = []\n",
    "for item in tqdm(balanced_test):\n",
    "    api_call = item['api_call']\n",
    "    api_response = item['api_response']\n",
    "    # curr_prompt = prompt_zero_shot.replace('<api_call>', api_call)\n",
    "    curr_prompt = prompt.replace('<api_call>', api_call)\n",
    "    curr_prompt = curr_prompt.replace('<api_response>', api_response)\n",
    "    # pred = make_gpt3_request(curr_prompt)['choices'][0]['message']['content']\n",
    "    # pred = make_gpt4_request(curr_prompt)['choices'][0]['message']['content']\n",
    "    # predictions_balanced_test.append(pred)\n",
    "    # time.sleep(2)\n",
    "\n",
    "    break\n",
    "    # with torch.no_grad():\n",
    "    #     tokenized = tokenizer(curr_prompt, return_tensors=\"pt\").input_ids\n",
    "    #     res = model.generate(tokenized, max_length=tokenized.shape[1] + 1)\n",
    "    #     pred = tokenizer.batch_decode(res)[0].removeprefix(tokenizer.batch_decode(tokenized)[0])\n",
    "    #     predictions_balanced_test.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes_contender',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'No',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'Yes',\n",
       " 'No',\n",
       " 'Yes',\n",
       " 'No']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_balanced_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions_balanced_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mpredictions_balanced_test\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions_balanced_test' is not defined"
     ]
    }
   ],
   "source": [
    "len(predictions_balanced_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75, Precision: 0.6226415094339622, Recall: 0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "answers_balanced_test = [item['label'] for item in balanced_test]\n",
    "\n",
    "acc = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tp = 0\n",
    "tn = 0\n",
    "for gt, pred in zip(answers_balanced_test, predictions_balanced_test):\n",
    "    if gt == pred:\n",
    "        acc += 1\n",
    "        if gt == 'Yes':\n",
    "            tn += 1\n",
    "        else:\n",
    "            tp += 1\n",
    "    elif gt == 'Yes' and pred == 'No':\n",
    "        fp += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "print(f'Accuracy: {acc}, Precision: {tp / (tp + fp)}, Recall: {tp / (tp + fn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
